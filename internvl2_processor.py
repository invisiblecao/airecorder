# internvl2_processor.py
import cv2
import numpy as np
from PIL import Image
from lmdeploy import pipeline, TurbomindEngineConfig
from lmdeploy.vl import load_image

# Initialize the InternVL2 model
model = 'OpenGVLab/InternVL2-8B'
internvl_pipe = pipeline(model, backend_config=TurbomindEngineConfig(session_len=8192))

def process_frame_with_internvl(frame_data):
    """
    Process the video frame with InternVL2 model to describe the image.
    
    Args:
        frame_data: Base64 encoded video frame.

    Returns:
        description: Text description generated by InternVL2.
    """
    try:
        # Decode the base64 video frame
        header, encoded = frame_data.split(',', 1)
        decoded_frame = base64.b64decode(encoded)

        # Convert to numpy array
        np_frame = np.frombuffer(decoded_frame, dtype=np.uint8)
        frame = cv2.imdecode(np_frame, cv2.IMREAD_COLOR)

        # Convert the frame to a format suitable for InternVL2
        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        # Load the image into InternVL2's format
        image_for_model = load_image(pil_image)
        
        # Send frame to InternVL2 model for image description
        internvl_response = internvl_pipe(('describe the image, focus on the face & body gestures, and the emotions', image_for_model))
        
        # Get the description from the model
        description = internvl_response.text.strip()
        
        return description
    
    except Exception as e:
        print(f"Error processing frame with InternVL2: {e}")
        return None